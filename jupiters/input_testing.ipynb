{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQYIffUvHTq6"
      },
      "outputs": [],
      "source": [
        "# Installation of the libraries which we'll use: HuggingFace Transformers, Datasets and Evaluate\n",
        "!pip install -q transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enMu7XTnzUUX"
      },
      "outputs": [],
      "source": [
        "# Installation of the paraphrase library\n",
        "!pip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akHy9lVIL2Me",
        "outputId": "3ee09191-bf44-4023-83b8-a9563e7d7a20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f08443a26b0>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from parrot import Parrot\n",
        "\n",
        "from tqdm import trange\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from random import sample\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Set the seed for random generation\n",
        "seed = 42\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9NBbZN8MbkM"
      },
      "outputs": [],
      "source": [
        "root = \"https://raw.githubusercontent.com/alfcan/CADOCS_NLU_Model/dev/dataset/augmented_dataset.csv\"\n",
        "\n",
        "df = pd.read_csv(root, sep = ';')\n",
        "label_mapping = {'get_smells': 0, 'get_smells_date': 1, 'report': 2, 'info': 3}\n",
        "df['intent'] = df['intent'].map(label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWfKp1wLtqIJ"
      },
      "outputs": [],
      "source": [
        "def paraphrase(phrase):\n",
        "    para_phrases = parrot.augment(input_phrase=phrase, use_gpu=False)\n",
        "    if para_phrases == None:\n",
        "      return None\n",
        "    else:\n",
        "      return para_phrases[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTus-bpVYyW9"
      },
      "outputs": [],
      "source": [
        "def remove_duplicate_rows(df, col1, col2):\n",
        "    # Compare the values of col1 and col2 columns\n",
        "    duplicates = df[col1].str.lower().str.strip().eq(df[col2].str.lower().str.strip())\n",
        "\n",
        "    # Remove duplicate rows\n",
        "    df_filtered = df[~duplicates]\n",
        "\n",
        "    return df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h3qKKaG-REf"
      },
      "outputs": [],
      "source": [
        "def plot(intent):\n",
        "  # Convert NumPy array to a Pandas Series object\n",
        "  intent_series = pd.Series(intent)\n",
        "\n",
        "  # Creates a bar graph for counting the occurrences of each unique value\n",
        "  intent_series.value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEkeTKk_rOQ-"
      },
      "outputs": [],
      "source": [
        "# Select 30% of rows randomly\n",
        "n_samples = int(len(df) * 0.3)\n",
        "selected_rows = sample(range(len(df)), n_samples)\n",
        "\n",
        "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")\n",
        "\n",
        "df_test = pd.DataFrame(columns=['original_request', 'paraphrased_request', 'intent'])\n",
        "\n",
        "# Apply paraphrasing and metamorphosis on selected rows\n",
        "for index, row in df.iloc[selected_rows].iterrows():\n",
        "    # Get the original request from the dataset\n",
        "    original_request = row['request']\n",
        "\n",
        "    print(index, original_request)\n",
        "\n",
        "    # Apply paraphrasing\n",
        "    paraphrased_request = paraphrase(original_request)\n",
        "    print(\"PARAPHRASE:\", paraphrased_request)\n",
        "\n",
        "    if paraphrased_request != None:\n",
        "      df_test = df_test.append({'original_request': original_request,\n",
        "                                'paraphrased_request': paraphrased_request,\n",
        "                                'intent': row['intent']}, ignore_index=True)\n",
        "\n",
        "print(df_test.head())\n",
        "df_test.to_csv(\"./df_input_testing_eng\", sep=\";\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSSOtZ2Do8JU"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\"df_input_testing_eng\", sep=\";\")\n",
        "\n",
        "# Call the function to remove duplicate or similar rows\n",
        "df_test = remove_duplicate_rows(df_test, 'original_request', 'paraphrased_request')\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnkVGdBsNYO9"
      },
      "outputs": [],
      "source": [
        "request = df_test.paraphrased_request.values\n",
        "intent = df_test.intent.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMGFLcha-e1L"
      },
      "outputs": [],
      "source": [
        "plot(intent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6LixxViPfab"
      },
      "outputs": [],
      "source": [
        "# Load the metrics\n",
        "import evaluate\n",
        "\n",
        "accuracy_metric = evaluate.load('accuracy')\n",
        "precision_metric = evaluate.load('precision')\n",
        "recall_metric = evaluate.load('recall')\n",
        "f1_metric = evaluate.load('f1')\n",
        "mcc_metric = evaluate.load('matthews_correlation')\n",
        "\n",
        "# Compute of metrics\n",
        "def compute_metrics(preds, label_ids):\n",
        "  accuracy = accuracy_metric.compute(predictions=preds, references=label_ids)['accuracy']\n",
        "  precision = precision_metric.compute(predictions=preds, references=label_ids, average=None)['precision']\n",
        "  precision_w = precision_metric.compute(predictions=preds, references=label_ids, average='weighted')['precision']\n",
        "  recall = recall_metric.compute(predictions=preds, references=label_ids, average=None)['recall']\n",
        "  recall_w = recall_metric.compute(predictions=preds, references=label_ids, average='weighted')['recall']\n",
        "  f1 = f1_metric.compute(predictions=preds, references=label_ids, average=None)['f1']\n",
        "  f1_w = f1_metric.compute(predictions=preds, references=label_ids, average='weighted')['f1']\n",
        "  mcc = mcc_metric.compute(predictions=preds, references=label_ids)['matthews_correlation']\n",
        "\n",
        "  return accuracy, precision, precision_w, recall, recall_w, f1, f1_w, mcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lnWXGGEb150"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"alfcan/CADOCS_NLU_eng\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcE71tSuYKLv"
      },
      "outputs": [],
      "source": [
        "# Tokenizer of RoBERTa\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\n",
        "    'roberta-base',\n",
        "    do_lower_case = True\n",
        ")\n",
        "\n",
        "def get_metrics(df, col_req, col_intent):\n",
        "  preds = []\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    request_ids = tokenizer.encode_plus(\n",
        "                              row[col_req],\n",
        "                              add_special_tokens = True,\n",
        "                              max_length = 32,\n",
        "                              pad_to_max_length = True,\n",
        "                              return_attention_mask = True,\n",
        "                              return_tensors = 'pt'\n",
        "                        )\n",
        "\n",
        "    input_ids = torch.clone(request_ids['input_ids']).detach().to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids)\n",
        "\n",
        "    predictions = torch.softmax(output.logits, dim=1)\n",
        "    confidence = predictions.max(dim=1).values.detach().cpu().numpy()\n",
        "    predicted_class = predictions.argmax(dim=1).flatten().cpu().numpy()\n",
        "\n",
        "    preds.append(predicted_class[0])\n",
        "\n",
        "  # Calculate test metrics\n",
        "  test_accuracy, test_precision, test_precision_w, test_recall, test_recall_w, test_f1, test_f1_w, test_mcc = compute_metrics(preds, df[col_intent].values)\n",
        "\n",
        "  print('- Test Accuracy: {:.4f}'.format(test_accuracy))\n",
        "\n",
        "  print('\\n- Test Precision weighted: {:.4f}'.format(test_precision_w))\n",
        "  print('\\t- Test Precision [class get_smell]: {:.4f}'.format(test_precision[0]))\n",
        "  print('\\t- Test Precision [class get_smell_date]: {:.4f}'.format(test_precision[1]))\n",
        "  print('\\t- Test Precision [class report]: {:.4f}'.format(test_precision[2]))\n",
        "  print('\\t- Test Precision [class info]: {:.4f}'.format(test_precision[3]))\n",
        "\n",
        "  print('\\n- Test Recall weighted: {:.4f}'.format(test_recall_w))\n",
        "  print('\\t- Test Recall [class get_smell]: {:.4f}'.format(test_recall[0]))\n",
        "  print('\\t- Test Recall [class get_smell_date]: {:.4f}'.format(test_recall[1]))\n",
        "  print('\\t- Test Recall [class report]: {:.4f}'.format(test_recall[2]))\n",
        "  print('\\t- Test Recall [class info]: {:.4f}'.format(test_recall[3]))\n",
        "\n",
        "  print('\\n- Test F1 weighted: {:.4f}'.format(test_f1_w))\n",
        "  print('\\t- Test F1 [class get_smell]: {:.4f}'.format(test_f1[0]))\n",
        "  print('\\t- Test F1 [class get_smell_date]: {:.4f}'.format(test_f1[1]))\n",
        "  print('\\t- Test F1 [class report]: {:.4f}'.format(test_f1[2]))\n",
        "  print('\\t- Test F1 [class info]: {:.4f}'.format(test_f1[2]))\n",
        "\n",
        "  print('\\n- Test MCC: {:.4f}\\n'.format(test_mcc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzg0R2tkykv_",
        "outputId": "02a17117-5fba-4549-ee28-d3a1b0416ae6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Test Accuracy: 0.9880\n",
            "\n",
            "- Test Precision weighted: 0.9884\n",
            "\t- Test Precision [class get_smell]: 0.9643\n",
            "\t- Test Precision [class get_smell_date]: 1.0000\n",
            "\t- Test Precision [class report]: 1.0000\n",
            "\t- Test Precision [class info]: 1.0000\n",
            "\n",
            "- Test Recall weighted: 0.9880\n",
            "\t- Test Recall [class get_smell]: 1.0000\n",
            "\t- Test Recall [class get_smell_date]: 0.5000\n",
            "\t- Test Recall [class report]: 1.0000\n",
            "\t- Test Recall [class info]: 1.0000\n",
            "\n",
            "- Test F1 weighted: 0.9861\n",
            "\t- Test F1 [class get_smell]: 0.9818\n",
            "\t- Test F1 [class get_smell_date]: 0.6667\n",
            "\t- Test F1 [class report]: 1.0000\n",
            "\t- Test F1 [class info]: 1.0000\n",
            "\n",
            "- Test MCC: 0.9823\n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_metrics(df_test, \"paraphrased_request\", \"intent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w0pS2nYoG6uo",
        "outputId": "e8787fa2-5385-4c94-bb24-757b0e2e600f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-43672b48-0691-43f3-98cd-848d6e59db4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>paraphrase</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hey CADOCS, tell which community smells are pr...</td>\n",
              "      <td>Hey CADOCS, tell which community smells are pr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CADOCS can you tell which community smells ar...</td>\n",
              "      <td>how can you tell if your link contains any com...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CADOCS can you tell which community smells ar...</td>\n",
              "      <td>can cadocs tell me what community smells are p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CADOCS can you tell which community smells ar...</td>\n",
              "      <td>can cadocs tell me which community smells are ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I would like to know what are the community sm...</td>\n",
              "      <td>i'd like to know what smells the community has...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43672b48-0691-43f3-98cd-848d6e59db4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43672b48-0691-43f3-98cd-848d6e59db4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43672b48-0691-43f3-98cd-848d6e59db4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            original  \\\n",
              "0  Hey CADOCS, tell which community smells are pr...   \n",
              "1   CADOCS can you tell which community smells ar...   \n",
              "2   CADOCS can you tell which community smells ar...   \n",
              "3   CADOCS can you tell which community smells ar...   \n",
              "4  I would like to know what are the community sm...   \n",
              "\n",
              "                                          paraphrase  intent  \n",
              "0  Hey CADOCS, tell which community smells are pr...       0  \n",
              "1  how can you tell if your link contains any com...       0  \n",
              "2  can cadocs tell me what community smells are p...       0  \n",
              "3  can cadocs tell me which community smells are ...       0  \n",
              "4  i'd like to know what smells the community has...       0  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfParaphrased = pd.read_csv(\"https://raw.githubusercontent.com/alfcan/CADOCS_NLU_Model/dev/dataset/paraphrased_dataset.csv\", sep = ';', names=[\"original\", \"paraphrase\", \"intent\"])\n",
        "\n",
        "dfParaphrased['intent'] = dfParaphrased['intent'].map(label_mapping)\n",
        "\n",
        "dfParaphrased.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "duwBMVVK-jLs",
        "outputId": "778847c9-fb81-49f9-bae4-d456140ae889"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(dfParaphrased['intent'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYjFHVQUyyyK",
        "outputId": "e2218f0c-8894-44e7-a63f-c2a2465aee25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Test Accuracy: 0.9714\n",
            "\n",
            "- Test Precision weighted: 0.9732\n",
            "\t- Test Precision [class get_smell]: 1.0000\n",
            "\t- Test Precision [class get_smell_date]: 1.0000\n",
            "\t- Test Precision [class report]: 1.0000\n",
            "\t- Test Precision [class info]: 0.9375\n",
            "\n",
            "- Test Recall weighted: 0.9714\n",
            "\t- Test Recall [class get_smell]: 0.8889\n",
            "\t- Test Recall [class get_smell_date]: 1.0000\n",
            "\t- Test Recall [class report]: 1.0000\n",
            "\t- Test Recall [class info]: 1.0000\n",
            "\n",
            "- Test F1 weighted: 0.9710\n",
            "\t- Test F1 [class get_smell]: 0.9412\n",
            "\t- Test F1 [class get_smell_date]: 1.0000\n",
            "\t- Test F1 [class report]: 1.0000\n",
            "\t- Test F1 [class info]: 1.0000\n",
            "\n",
            "- Test MCC: 0.9595\n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_metrics(dfParaphrased, \"paraphrase\", \"intent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siVNGGNDIo9J",
        "outputId": "96536031-ccf3-40d1-96df-781375c41f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct class: get_smells --- Predicted class: get_smells --- Hey CADOCS, tell which community smells are present in the repository LINK ?\n",
            " Confidence: [0.9987966] --- Difference between original confidence and paraphrased confidence: [0.]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: get_smells --- how can you tell if your link contains any community smells?\n",
            " Confidence: [0.85550046] --- Difference between original confidence and paraphrased confidence: [0.1432141]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: get_smells --- can cadocs tell me what community smells are present in the link?\n",
            " Confidence: [0.99852055] --- Difference between original confidence and paraphrased confidence: [0.00019401]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: get_smells --- can cadocs tell me which community smells are present in the link?\n",
            " Confidence: [0.9985897] --- Difference between original confidence and paraphrased confidence: [0.00012487]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: get_smells --- i'd like to know what smells the community has in this link\n",
            " Confidence: [0.9987571] --- Difference between original confidence and paraphrased confidence: [-3.5703182e-05]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: get_smells --- i'd like to know what the community smells in this link\n",
            " Confidence: [0.9987834] --- Difference between original confidence and paraphrased confidence: [-6.198883e-05]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: get_smells --- i would like to know what the community smell in this link\n",
            " Confidence: [0.9988109] --- Difference between original confidence and paraphrased confidence: [-8.946657e-05]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: get_smells --- What are the community smells in the LINK project?\"\n",
            " Confidence: [0.9987857] --- Difference between original confidence and paraphrased confidence: [0.]\n",
            "\n",
            "Correct class: get_smells --- Predicted class: info --- is there a community smell link?\n",
            " Confidence: [0.99745446] --- Difference between original confidence and paraphrased confidence: [0.0005542]\n",
            "\n",
            "Correct class: get_smells_date --- Predicted class: get_smells_date --- Hey CADOCS,  tell which community smells are present in the repository LINK after 03/23/2019\n",
            " Confidence: [0.99920064] --- Difference between original confidence and paraphrased confidence: [0.]\n",
            "\n",
            "Correct class: get_smells_date --- Predicted class: get_smells_date --- if you see any community smells listed in the repository link on 01162028 can you use gtks to search for them?\n",
            " Confidence: [0.9990687] --- Difference between original confidence and paraphrased confidence: [0.00012887]\n",
            "\n",
            "Correct class: get_smells_date --- Predicted class: get_smells_date --- I would like to know what ate the community smells in this repo LINK starting from this date MM/DD/YYYY\n",
            " Confidence: [0.99921596] --- Difference between original confidence and paraphrased confidence: [0.]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- Hello CADOCS, I need a report of your last execution\n",
            " Confidence: [0.9992964] --- Difference between original confidence and paraphrased confidence: [0.]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- give me a report of your last execution\n",
            " Confidence: [0.9992854] --- Difference between original confidence and paraphrased confidence: [6.377697e-06]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- can you provide me with a report on your last execution?\n",
            " Confidence: [0.9992791] --- Difference between original confidence and paraphrased confidence: [1.3768673e-05]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- can you give me a report on your last execution?\n",
            " Confidence: [0.9992582] --- Difference between original confidence and paraphrased confidence: [3.46303e-05]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- can you provide a report about the last execution\n",
            " Confidence: [0.9992329] --- Difference between original confidence and paraphrased confidence: [-2.5331974e-05]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- i need a report from the last execution\n",
            " Confidence: [0.99920577] --- Difference between original confidence and paraphrased confidence: [5.6624413e-06]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- i need a report on the last execution\n",
            " Confidence: [0.9992093] --- Difference between original confidence and paraphrased confidence: [2.1457672e-06]\n",
            "\n",
            "Correct class: report --- Predicted class: report --- i need a report of the last execution\n",
            " Confidence: [0.99921405] --- Difference between original confidence and paraphrased confidence: [-2.6226044e-06]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- can you tell me more about the community scents that you can detect?\n",
            " Confidence: [0.9991185] --- Difference between original confidence and paraphrased confidence: [1.680851e-05]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- can you tell me more about the community smells you can detect?\n",
            " Confidence: [0.99913824] --- Difference between original confidence and paraphrased confidence: [-2.9206276e-06]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- hey cadocs can you tell me more about community smells you can detect?\n",
            " Confidence: [0.999106] --- Difference between original confidence and paraphrased confidence: [2.9325485e-05]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- what smells are you able to find in your community?\n",
            " Confidence: [0.9930381] --- Difference between original confidence and paraphrased confidence: [0.00505495]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- what smells do you have?\n",
            " Confidence: [0.998326] --- Difference between original confidence and paraphrased confidence: [-0.00023293]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- tell me the community smells?\n",
            " Confidence: [0.99906] --- Difference between original confidence and paraphrased confidence: [-0.00096691]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- is there any kind of smell which can be detected by cadocs?\n",
            " Confidence: [0.9990257] --- Difference between original confidence and paraphrased confidence: [3.5107136e-05]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- what types of community smells are possible with cadocs?\n",
            " Confidence: [0.9916255] --- Difference between original confidence and paraphrased confidence: [0.00743532]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- are there any kind of smells in the community in cadocs?\n",
            " Confidence: [0.9986755] --- Difference between original confidence and paraphrased confidence: [0.00038528]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- what does cadocs smell?\n",
            " Confidence: [0.9977483] --- Difference between original confidence and paraphrased confidence: [0.0012868]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- what smell do you see?\n",
            " Confidence: [0.9979388] --- Difference between original confidence and paraphrased confidence: [0.00109631]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- what local smells can you detect?\n",
            " Confidence: [0.99889874] --- Difference between original confidence and paraphrased confidence: [0.00013638]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- tell me the community smell?\n",
            " Confidence: [0.99897647] --- Difference between original confidence and paraphrased confidence: [0.00013071]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- what are community smells?\n",
            " Confidence: [0.99870384] --- Difference between original confidence and paraphrased confidence: [0.00040334]\n",
            "\n",
            "Correct class: info --- Predicted class: info --- tell me the community smells?\n",
            " Confidence: [0.99906] --- Difference between original confidence and paraphrased confidence: [4.720688e-05]\n",
            "\n",
            "Percentage get_smells: 0.8888888888888888\n",
            "Percentage get_smells_date: 1.0\n",
            "Percentage report: 1.0\n",
            "Percentage info: 1.0\n",
            "Weighted average: 0.9714285714285714\n"
          ]
        }
      ],
      "source": [
        "dfParaphrased = pd.read_csv(\"https://raw.githubusercontent.com/alfcan/CADOCS_NLU_Model/dev/dataset/paraphrased_dataset.csv\", sep = ';', names=[\"original\", \"paraphrase\", \"intent\"])\n",
        "\n",
        "correct_get_smells, correct_get_smells_date, correct_report, correct_info=0, 0, 0, 0\n",
        "\n",
        "total_get_smells, total_get_smells_date, total_report, total_info=0, 0, 0, 0\n",
        "\n",
        "for index, row in dfParaphrased.iterrows():\n",
        "  request_original=row[\"original\"]\n",
        "  request=row[\"paraphrase\"]\n",
        "  intent=row[\"intent\"]\n",
        "\n",
        "  request_ids = tokenizer.encode_plus(\n",
        "                          request,\n",
        "                          add_special_tokens = True,\n",
        "                          max_length = 32,\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_tensors = 'pt'\n",
        "                    )\n",
        "\n",
        "  input_ids = torch.clone(request_ids['input_ids']).detach().to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      output = model(input_ids)\n",
        "\n",
        "  predictions = torch.softmax(output.logits, dim=1)\n",
        "  confidence = predictions.max(dim=1).values.detach().cpu().numpy()\n",
        "  predicted_class = predictions.argmax(dim=1).flatten().cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "  request_original_ids = tokenizer.encode_plus(\n",
        "                          request_original,\n",
        "                          add_special_tokens = True,\n",
        "                          max_length = 32,\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_tensors = 'pt'\n",
        "                    )\n",
        "\n",
        "  input_original_ids = torch.clone(request_original_ids['input_ids']).detach().to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      output_original = model(input_original_ids)\n",
        "\n",
        "  predictions_original = torch.softmax(output_original.logits, dim=1)\n",
        "  confidence_original = predictions_original.max(dim=1).values.detach().cpu().numpy()\n",
        "  predicted_original_class = predictions_original.argmax(dim=1).flatten().cpu().numpy()\n",
        "\n",
        "  if confidence < 0.55:\n",
        "    print(\"NOT ENOUGH CONFIDENCE TO ANSWER\")\n",
        "\n",
        "  for label, index in label_mapping.items():\n",
        "      if index == predicted_class:\n",
        "          predicted_label = label\n",
        "          break\n",
        "  for label, index in label_mapping.items():\n",
        "      if index == predicted_original_class:\n",
        "          predicted_original_label = label\n",
        "          break\n",
        "\n",
        "  if intent == \"get_smells\":\n",
        "    total_get_smells=total_get_smells+1\n",
        "    if intent == predicted_label == predicted_original_label and confidence_original-confidence < 0.2:\n",
        "        correct_get_smells=correct_get_smells+1\n",
        "  elif intent == \"get_smells_date\":\n",
        "    total_get_smells_date=total_get_smells_date+1\n",
        "    if intent == predicted_label == predicted_original_label and confidence_original-confidence < 0.2:\n",
        "        correct_get_smells_date=correct_get_smells_date+1\n",
        "  elif intent == \"report\":\n",
        "    total_report=total_report+1\n",
        "    if intent == predicted_label == predicted_original_label and confidence_original-confidence < 0.2:\n",
        "        correct_report=correct_report+1\n",
        "  elif intent == \"info\":\n",
        "    total_info=total_info+1\n",
        "    if intent == predicted_label == predicted_original_label and confidence_original-confidence < 0.2:\n",
        "        correct_info=correct_info+1\n",
        "\n",
        "\n",
        "  print(\"Correct class: \" + intent + \" --- Predicted class: \" + predicted_label + \" --- \" + request+\"\\n Confidence: \"+str(confidence)+\" --- Difference between original confidence and paraphrased confidence: \"+str(confidence_original-confidence)+\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "percentage_get_smells=correct_get_smells/total_get_smells\n",
        "percentage_get_smells_date=correct_get_smells_date/total_get_smells_date\n",
        "percentage_report=correct_report/total_report\n",
        "percentage_info=correct_info/total_info\n",
        "print(\"Percentage get_smells: \"+ str(percentage_get_smells))\n",
        "print(\"Percentage get_smells_date: \"+ str(percentage_get_smells_date))\n",
        "print(\"Percentage report: \"+ str(percentage_report))\n",
        "print(\"Percentage info: \"+ str(percentage_info))\n",
        "sum_of_requests= total_get_smells + total_get_smells_date + total_report + total_info\n",
        "weighted_average=((percentage_get_smells*total_get_smells)+(percentage_get_smells_date*total_get_smells_date)+(percentage_report*total_report)+(percentage_info*total_info))/(sum_of_requests)\n",
        "print(\"Weighted average: \"+str(weighted_average))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
